{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6168d00",
   "metadata": {},
   "source": [
    "---\n",
    "title: Mistral Demo\n",
    "format:\n",
    "    html:\n",
    "        code-fold: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d53579c9-3f79-4482-b687-8268c55d1e4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_DATASETS_CACHE=/pscratch/sd/a/azaidi/llm/cache\n",
      "env: HF_HOME=/pscratch/sd/a/azaidi/llm/cache\n"
     ]
    }
   ],
   "source": [
    "### do not run this cell block unless using Perlmutter\n",
    "#| echo: false\n",
    "#| output: false\n",
    "%env HF_DATASETS_CACHE=/pscratch/sd/a/azaidi/llm/cache\n",
    "%env HF_HOME=/pscratch/sd/a/azaidi/llm/cache\n",
    "cache_dir = '/pscratch/sd/a/azaidi/llm/cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58cd6d51-277d-43ae-a315-2ef3afa2db30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "#| output: false\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import requests\n",
    "import torch\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab8a4c4-2aeb-4f36-9050-fae0deeb6376",
   "metadata": {},
   "source": [
    "First lets setup a function to call the [DCE](https://metadata.namesforlife.com) in order to get the full text of our desired articles. This function will return the full text of the article in question by default. If you would prefer to receive the metadata, you can set the `full_text` field to False\n",
    "\n",
    "- In order to get the full-text -- you need to provide the pubmed `central` ID <br>\n",
    "- In order to get the metadata -- you need to provide the pubmed ID\n",
    "<br><br>\n",
    "\n",
    "By default, our function will pull one of our main reference papers --> pmid: 31801294 / pmcid: PMC6955870\n",
    "- Paper title: \"Comparative Genomics Reveals Metabolic Specificity of Endozoicomonas Isolated from a Marine Sponge and the Genomic Repertoire for Host-Bacteria Symbioses.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab2479b7-ecaa-45f3-81ae-4e405fb66973",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "#| output: false\n",
    "def call_dce(url=None, pmid=None, pmcid=None, full_text=True):\n",
    "    if pmid is None: pmid = '31801294'\n",
    "    if pmcid is None: pmcid = 'PMC6955870'\n",
    "    if url is None: \n",
    "        if full_text: url = \"https://metadata.namesforlife.com/context?pmcid=\" + pmcid\n",
    "        else: url = \"https://metadata.namesforlife.com/reference?pmid=\" + pmid\n",
    "    return requests.get(url).text, pmid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c36b47fe-3bed-4bf5-88f7-cc9c16113f5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37995,\n",
       " 'Sponges (Phylum Porifera) interact and co-evolve with microbes belonging to different lineages.\\nDesp')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: false\n",
    "txt, pmid = call_dce(full_text=True)\n",
    "len(txt), txt[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efc55a7d-b3a0-465b-8255-0cc66e386244",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"title\":\"Comparative Genomics Reveals Metabolic Specificity of Endozoicomonas Isolated from a Marine Sponge and the Genomic Repertoire for Host-Bacteria Symbioses\",\"doi\":\"10.3390/microorganisms7120635\",\"pmc\":\"PMC6955870\",\"pmid\":\"31801294\",\"date\":\"2019-12-01\",\"authors\":[],\"publication_title\":\"Microorganisms\",\"publication_abbrev\":\"Microorganisms\",\"publication_issn\":null,\"volume\":null,\"issue\":null,\"e_location\":null,\"first_page\":null,\"last_page\":null}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_dce(full_text=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36fac7f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "#| output: false\n",
    "def get_assets(model_name, four_bit=False, eigth_bit=False, cache_dir=None):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
    "                                            cache_dir=cache_dir,\n",
    "                                            load_in_8bit=eigth_bit,\n",
    "                                            load_in_4bit=four_bit)\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                            cache_dir=cache_dir,\n",
    "                                            load_in_4bit=four_bit,\n",
    "                                            load_in_8bit=eigth_bit\n",
    "                                            );\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c52bf94f-a011-4381-9e76-71336da7607d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model_name = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd8091c0-e118-40c1-87b5-1f09d3ebbe7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| echo: True\n",
    "# Do we want to quantize our model?\n",
    "four_bit = False\n",
    "eight_bit = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eef6e538",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "734b9a81496e490f8de744457b61e07a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: false\n",
    "tokenizer, model = get_assets(model_name=model_name, four_bit=four_bit, cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706576cb-e207-4ebe-a031-0deca891bada",
   "metadata": {},
   "source": [
    "Lets take a look at our Mistral model [Mixtral-7B-Instruct-v0.2](https://huggingface.co/mistralai/Mixtral-8x7B-v0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fac5517-1924-4f35-8f96-db6a4c218236",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: true\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5cffc52-6eff-40ee-9cb1-1294b65fb721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now that we have our model, we can move it onto the GPU (if it's available)\n",
    "if (torch.cuda.is_available() | ~four_bit | ~eight_bit): \n",
    "    model.to('cuda');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d448e39b-f7a4-4039-907f-c0461fa1a07d",
   "metadata": {},
   "source": [
    "Before feeding any text into our model, lets just quickly get a sense of how our tokenizer will break down our text into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f7c8711-8ea6-4afc-ae21-3d74a7e21089",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our text has 5166 individual words (separated by white space) --> this gets broken out into 10866 tokens via our tokenization process\n"
     ]
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: false\n",
    "num_words = len(txt.split(' '))\n",
    "num_tokens = len(tokenizer(txt).input_ids)\n",
    "print(f'Our text has {num_words} individual words (separated by white space) --> this gets broken out into {num_tokens} tokens via our tokenization process')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b352047-1232-4c65-89d2-d1784ab19dd9",
   "metadata": {},
   "source": [
    "### Now lets declare a function that will tokenize our text and generate a response to the given text, based on the parameters we choose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69acd4cc-c899-48b9-9010-778f834e0a2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "#| output: false\n",
    "\n",
    "def get_response(prompt, new_tokens=250, rep_penalty=1.0, length_penalty=1.0, device=None):\n",
    "    if model.device.type == 'cuda': device = 'cuda'\n",
    "    else: device = 'cpu'\n",
    "    inputs = tokenizer(prompt,return_tensors=\"pt\").to(device)\n",
    "    output = tokenizer.batch_decode(model.generate(inputs=inputs['input_ids'],\n",
    "                                                   max_new_tokens=new_tokens,\n",
    "                                                   repetition_penalty=rep_penalty,\n",
    "                                                   length_penalty=length_penalty,\n",
    "                                                   pad_token_id=tokenizer.eos_token_id), \n",
    "                                    skip_special_tokens=True, \n",
    "                                    clean_up_tokenization_spaces=False)[0]\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "652f366d-4853-40b7-b5ca-e586ba2f7a11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"The ostrich pooped its pants while walking across the street. But, the Tyrannosaurus rex was one of the most ferocious predators to ever walk the Earth. With a massive body, sharp teeth, and jaws so powerful they could crush a car, this famous carnivore dominated the forested river valleys in western North America during the late Cretaceous period, 68 million years ago. \\n \\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6798d925-237a-447d-b12c-62d9b22d93e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what was the previous text about? \n",
      "The ostrich pooped its pants while walking across the street. But, the Tyrannosaurus rex was one of the most ferocious predators to ever walk the Earth. With a massive body, sharp teeth, and jaws so powerful they could crush a car, this famous carnivore dominated the forested river valleys in western North America during the late Cretaceous period, 68 million years ago. \n",
      " \n",
      "The previous text was about an ostrich having an accident and the description of a Tyrannosaurus rex, a dinosaur known for its ferocity and dominance during the late Cretaceous period.\n"
     ]
    }
   ],
   "source": [
    "get_response(prompt=f'what was the previous text about? \\n{prompt}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6681bd-ac7a-4ae6-846e-d780bc8db6a7",
   "metadata": {},
   "source": [
    "### That seems to make sense -- now lets build a more useful and relevant prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53888f75-b3f7-4c7c-8f93-e87baff81917",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_prompt(questions, input_text):\n",
    "    return f\"[INST] You are a microbiology journal editor. Please answer as concisely as possible: {questions} \\n here is the text in question: {input_text} \\n [/INST]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "05581e74-9f51-4aec-89be-48454cd9d8e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] You are a microbiology journal editor. Please answer as concisely as possible: can you provide the exact quote surrounding a mention of GCA_00092485.1? \n",
      " here is the text in question: Sponges (Phylum Porifera) interact and co-evolve with microbes belonging to different lineages.\n",
      "Despite the ubiquity of microbes in a wide range of environments, associations between sponge and microbes are not random and often result in sharing of the resources in a particular niche.\n",
      "Moreover, sponge-associated bacteria play a crucial role in sponge biology, metabolism, and ecology [1].\n",
      "Studies using whole-genome sequencing of microbes isolated from sponges and metagenomic binning approaches have shown the genomic and molecular mechanisms involved in the successful association between the sponges and symbiotic microbes.\n",
      "For instance, genome streamlining [2], evolution of bacterial genome through transposable insertion elements [3], presence of adhesion-related genes, the genes encoding eukaryotic-like protein, effector/virulence factors [4,5,6,7] were reported among several sponge-associated bacteria.\n",
      "Since the first description of the genus Endozoicomonas (Gammaproteobacteria; Oceanospirillales) isolated from the sea slug Elysia ornate [8], Endozoicomonas has been widely reported to be found in association with different marine invertebrates.\n",
      "For instance, several studies reported the presence of Endozoicomonas in sponges, tunicates, cnidarians, annelids, molluscs, and fishes [9,10,11,12,13,14] across large geographical scales (see the review by [15] for further details).\n",
      "Several studies found the predominance of Endozoicomonas in healthy Mediterranean gorgonians—Paramuricea clavata and coral—Porites astreoides when compared to their diseased counterparts [16,17], suggesting that strains belonging to this genus have been considered to be an integral part of the healthy holobiont.\n",
      "Though numerous studies based on culture-independent analyses using the 16S rRNA (ribosomal RNA) genes have detected the distribution and abundance of Endozoicomonas, there are very few reports investigating the physiological capabilities and genomic features of these enigmatic bacterial members of the genus Endozoicomonas due to the difficulties in isolation/culturing from the host tissues.\n",
      "So far, only 11 draft genomes of Endozoicomonas isolated from sponges, tunicates, coral, mollusc, bryozoa, and fishes are publicly available.\n",
      "Analysis of the draft genomes obtained from bacterial isolates, single cell genomics, and metagenomic binning approaches suggest that Endozoicomonas genomes are encoded with a higher frequency of repeat sequences indicating various stages of genome erosion, possible mechanisms involved in host-endosymbiont relationship, enrichment of genes responsible for transporter activity, protein secretion, and transposase, and niche-specific changes through the expansion of virulence genes and loss of metabolic functions [14,18,19].\n",
      "Despite the abovementioned features detected in the genomes of coral- and fish-associated Endozoicomonas, little genomic information is available for sponge-associated Endozoicomonas.\n",
      "In this study we sequenced a high-quality draft genome of Endozoicomonas sp. OPT23 isolated from the intertidal marine sponge Ophlitaspongia papilla and performed a comprehensive comparative genomics analysis with other members (n = 11) of the genus to unravel the genomic signatures of the sponge-associated Endozoicomonas sp. OPT23.\n",
      "Endozoicomonas sp. OPT23 was isolated from the intertidal marine sponge O. papilla (Demospongiae) collected from the Atlantic coast of Portugal.\n",
      "Approximately 1 cm3 of sponge tissue was washed to remove the loosely associated microbes and other debris, followed by grinding using sterile seawater.\n",
      "The homogenate was serially diluted and spread plated on DifcoTM Marine Agar 2216(BD Difco, United Kingdom) \n",
      " [/INST] The text mentions GCA_00092485.1 in relation to the publicly available draft genomes of Endozoicomonas, but an exact quote is not provided. However, the text states that there are only 11 draft genomes of Endozoicomonas publicly available, including the one from GCA_00092485.1.\n"
     ]
    }
   ],
   "source": [
    "get_response(prompt=build_prompt(questions=\"can you provide the exact quote surrounding a mention of GCA_00092485.1?\",\n",
    "             input_text=call_dce(full_text=True)[0][:3700],),\n",
    "             new_tokens=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb873b0f-18ab-4ee4-873a-e861bd658c44",
   "metadata": {},
   "source": [
    "Some work left to be done to make this more sensible and workable :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fca1a8-dda2-4e73-a667-4370de4b6d92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#mistral prompt format\n",
    "# <s>[INST] Instruction [/INST] Model answer</s>[INST] Follow-up instruction [/INST]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d82d7f7-fd1b-4d54-9a1f-50d3843e1288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#prompt = f'<s>[INST] Can you summarize this text? {sample_text} [/INST]'\n",
    "#prompt = f'<s>[INST] {text} [/INST]'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
