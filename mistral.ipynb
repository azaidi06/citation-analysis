{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d53579c9-3f79-4482-b687-8268c55d1e4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_DATASETS_CACHE=/pscratch/sd/a/azaidi/llm/cache\n",
      "env: HF_HOME=/pscratch/sd/a/azaidi/llm/cache\n"
     ]
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: false\n",
    "%env HF_DATASETS_CACHE=/pscratch/sd/a/azaidi/llm/cache\n",
    "%env HF_HOME=/pscratch/sd/a/azaidi/llm/cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58cd6d51-277d-43ae-a315-2ef3afa2db30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "#| output: false\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import requests\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba9be353-d4ec-4c6c-8955-674963db44d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_models(parent_name):\n",
    "    cache_dir = '/pscratch/sd/a/azaidi/llm/cache/models--'\n",
    "    models = [path.split('--')[-1] for path in \\\n",
    "              glob.glob(cache_dir + parent_name)]\n",
    "    print(f'the {parent_name} models are: {models}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8acab03d-a7bb-499d-aeee-f72ee471801e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mistralai* models are: ['Mistral-7B-v0.1', 'Mixtral-8x7B-Instruct-v0.1', 'Mistral-7B-Instruct-v0.2']\n",
      "the meta-llama* models are: ['Llama-2-7b-hf', 'Llama-2-70b-hf', 'Llama-2-70b-chat-hf']\n"
     ]
    }
   ],
   "source": [
    "get_models('mistralai*'), get_models('meta-llama*'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab2479b7-ecaa-45f3-81ae-4e405fb66973",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "#| output: false\n",
    "def call_dce(url=None, pmid=None, context=False):\n",
    "    if pmid is None: pmid = 'PMC6000758'\n",
    "    if url is None: \n",
    "        if context: url = \"https://metadata.namesforlife.com/context?pmcid=\" + pmid\n",
    "        else: url = \"https://metadata.namesforlife.com/reference?pmcid=\" + pmid\n",
    "    return requests.get(url).text, pmid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c36b47fe-3bed-4bf5-88f7-cc9c16113f5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37593, 'PMC6000758')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: false\n",
    "txt, pmid = call_dce(context=True)\n",
    "len(txt), pmid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36fac7f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "#| output: false\n",
    "def get_assets(model_name, four_bit=False, eigth_bit=False):\n",
    "    cache_dir = '/pscratch/sd/a/azaidi/llm/cache'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
    "                                            cache_dir=cache_dir,\n",
    "                                            load_in_8bit=eigth_bit,\n",
    "                                            load_in_4bit=four_bit)\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                            cache_dir=cache_dir,\n",
    "                                            load_in_4bit=four_bit,\n",
    "                                            load_in_8bit=eigth_bit\n",
    "                                            );\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eef6e538",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64fdcd16ee148b4ac6187c9fbdf98ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c19f0367513422f91afe0b6c75f756e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: false\n",
    "tokenizer, model = get_assets(\"mistralai/Mixtral-8x7B-Instruct-v0.1\", four_bit=True)\n",
    "#tokenizer, model = get_assets(\"mistralai/Mistral-7B-Instruct-v0.2\", four_bit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fac5517-1924-4f35-8f96-db6a4c218236",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MixtralForCausalLM(\n",
       "  (model): MixtralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MixtralDecoderLayer(\n",
       "        (self_attn): MixtralSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MixtralRotaryEmbedding()\n",
       "        )\n",
       "        (block_sparse_moe): MixtralSparseMoeBlock(\n",
       "          (gate): Linear4bit(in_features=4096, out_features=8, bias=False)\n",
       "          (experts): ModuleList(\n",
       "            (0-7): 8 x MixtralBlockSparseTop2MLP(\n",
       "              (w1): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (w2): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "              (w3): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_layernorm): MixtralRMSNorm()\n",
       "        (post_attention_layernorm): MixtralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MixtralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: true\n",
    "#| output: true\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5cffc52-6eff-40ee-9cb1-1294b65fb721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model.to('cuda');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69acd4cc-c899-48b9-9010-778f834e0a2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "#| output: false\n",
    "\n",
    "def get_response(prompt, new_tokens=250, rep_penalty=1.0, length_penalty=1.0, device=None):\n",
    "    if model.device.type == 'cuda': device = 'cuda'\n",
    "    else: device = 'cpu'\n",
    "    inputs = tokenizer(prompt,return_tensors=\"pt\").to(device)\n",
    "    output = tokenizer.batch_decode(model.generate(inputs=inputs['input_ids'],\n",
    "                                                   max_new_tokens=new_tokens,\n",
    "                                                   repetition_penalty=rep_penalty,\n",
    "                                                   length_penalty=length_penalty,\n",
    "                                                   pad_token_id=tokenizer.eos_token_id), \n",
    "                                    skip_special_tokens=True, \n",
    "                                    clean_up_tokenization_spaces=False)[0]\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70f6c1e7-7187-406a-a566-0dc5e50823eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37593, 12299)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(txt), tokenizer(txt).input_ids.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "652f366d-4853-40b7-b5ca-e586ba2f7a11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"The ostrich shit its pants while walking across the street. But, the Tyrannosaurus rex was one of the most ferocious predators to ever walk the Earth. With a massive body, sharp teeth, and jaws so powerful they could crush a car, this famous carnivore dominated the forested river valleys in western North America during the late Cretaceous period, 68 million years ago. \\n \\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6798d925-237a-447d-b12c-62d9b22d93e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pscratch/sd/a/azaidi/.conda/envs/dl/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:226: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what was the previous text about? \n",
      "The ostrich shit its pants while walking across the street. But, the Tyrannosaurus rex was one of the most ferocious predators to ever walk the Earth. With a massive body, sharp teeth, and jaws so powerful they could crush a car, this famous carnivore dominated the forested river valleys in western North America during the late Cretaceous period, 68 million years ago. \n",
      " \n",
      "\n",
      "The previous text was about the Tyrannosaurus rex, a large carnivorous dinosaur that lived during the late Cretaceous period. The text describes its massive body, sharp teeth, and powerful jaws, and mentions that it was one of the most ferocious predators to ever walk the Earth. It does not mention the ostrich or its pants.\n"
     ]
    }
   ],
   "source": [
    "get_response(prompt=f'what was the previous text about? \\n{prompt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8058f575-9f3c-4437-acea-6fb4ccbe614b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37593, 'PMC6000758')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt, pmid = call_dce(context=True)\n",
    "len(txt), pmid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e15b7b2-2821-4fa2-9e2e-23c45bee5100",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tokenizer.encode([1,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d96d6996-597e-4acf-bac8-65af9ddeb894",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1,   415, 13993,  ...,   302,  2145, 28723]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(txt,return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01960093-18de-4003-af00-5119580c8bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53888f75-b3f7-4c7c-8f93-e87baff81917",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_prompt(questions, input_text):\n",
    "    return f\"[INST] You are a microbiology journal editor. Please answer as concisely as possible: {questions} \\n here is the text in question: {input_text} \\n [/INST]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05581e74-9f51-4aec-89be-48454cd9d8e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] You are a microbiology journal editor. Please answer as concisely as possible: can you provide the exact quote surrounding a mention of GCA_00092485.1? \n",
      " here is the text in question: The ocean covers 71% of the earth’s surface and is regarded as the largest habitat for life on the planet Earth.\n",
      "Marine microorganisms are known to play an essential role in energy conservation and biogeochemical cycling in the oceans.\n",
      "Heterotrophic prokaryotes are considered key players in the decomposition of the dissolved organic matter (DOM) and particulate organic matter (POM) present therein (DeLong and Karl, 2005; Azam and Malfatti, 2007).\n",
      "Oceanospirillales is an order of proteobacteria with seven families of heterotrophic marine bacteria that are usually associated with oil spills and are known to be involved in xylan and hydrocarbon utilization (Choi et al., 2012; Cao et al., 2014).\n",
      "Recently, a new family named Kangiellaceae has been proposed within the order Oceanospirillales based on phylogenetic, chemotaxonomic and physiological characteristics; this family comprises three genera: Kangiella, Aliikangiella, and Pleionea (Wang et al., 2015).\n",
      "Although the Kangiella genus was reclassified within Kangiellaceae instead of Alcanivoracaceae based on 16S rRNA gene phylogeny (Wang et al., 2015), taxonomic signatures at the genomic level are still needed.\n",
      "Kangiella are gram-negative long rods that are non-motile and non-spore-forming bacteria.\n",
      "Nine strains belonging to the genus Kangiella have been isolated from various marine environments, including marine sand (Kim et al., 2015), tidal flat sediments and coastal regions (Yoon et al., 2004, 2012; Romanenko et al., 2010; Ahn et al., 2011; Jean et al., 2012; Lee et al., 2013).\n",
      "For example, both K. koreensis DSM 16069 and Kangiella aquimarina DSM 16071 were isolated from tidal flat sediment at Daepo Beach, Yellow Sea, Korea, and were shown to grow optimally at 30–37°C and pH 7.0–8.0 (Yoon et al., 2004).\n",
      "K. sediminilitoris KCTC 23892 was isolated from tidal flat sediment from the South Sea in South Korea, which was shown to grow optimally at 30–37°C and pH 7.0–7.5 (Lee et al., 2013).\n",
      "Kangiella geojedonensis KCTC 23420 was isolated from seawater off the southern coast of Korea, and was shown to grow optimally at 10–40°C and pH 7.0–7.5 (Yoon et al., 2004).\n",
      "Recently, we isolated a novel strain named Kangiella profundi from a deep sea sediment sample that was collected from the southwest Indian Ocean at a depth of 2784 m (Xu et al., 2015).\n",
      "Due to limited research, our understanding about the metabolic potential and ecological functions of bacteria belonging to the family Kangiellaceae is still obscure.\n",
      "To date, no genome has been completely sequenced from either of the two genera Aliikangiella and Pleionea.\n",
      "Moreover, only three completely sequenced genomes of the genus Kangiella, i.e., K. koreensis DSM 16069 (GenBank accession: GCA_000024085.1), K. sediminilitoris KCTC 23892 (GenBank accession: GCA_001708405.1), and K. geojedonensis KCTC 23420 (GenBank accession: GCA_000981765.1), are available.\n",
      "In this study, we report the complete genome sequence of K. profundi FT102 (GenBank accession: CP025120).\n",
      "Comparative genomics-based approaches were utilized to explore the metabolic potential of Kangiella.\n",
      "We show that featured genomic reduction in Kangiella is due to low genomic redundancy as well as Kangiella lineage-specific gene loss.\n",
      "The metabolic base of Kangiella as a powerful extracellular protein degrader was investigated.\n",
      "Our study provides the first insights into the genomic and metabolic capabilities of Kangiella.\n",
      "Kangiella profundi FT102T ( = CGMCC 1.12959T = KCTC 42297T = JCM 30232T) is from our laboratory stock.\n",
      "The strains K. koreensis DSM 16069 (JCM 12317), K. aquimarina DSM 16071 (JCM 12318) and K. geojedonensis KCTC 23420 were obtained from Japan Collection of Microorganisms (J \n",
      " [/INST] The exact quote surrounding the mention of GCA_000924085.1 is: \"only three completely sequenced genomes of the genus Kangiella, i.e., K. koreensis DSM 16069 (GenBank accession: GCA_000024085.1), K. sediminilitoris KCTC 23892 (GenBank accession: GCA_001708405.1), and K. geojedonensis KCTC 23420 (GenBank accession: GCA_000981765.1), are available.\" This indicates that the genome of K. koreensis DSM 16069, with GenBank accession GCA_000024085.1, has been completely sequenced.\n"
     ]
    }
   ],
   "source": [
    "get_response(prompt=build_prompt(questions=\"can you provide the exact quote surrounding a mention of GCA_00092485.1?\",\n",
    "             input_text=call_dce(context=True)[0][:3700],),\n",
    "             new_tokens=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "37af9855-9cff-447d-8416-118e44b510a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get_response(prompt=f'can you provide the exact quote surrounding a mention of GCA_000024085.1? Please provide the sentence before and after. \\n{txt} -------\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fca1a8-dda2-4e73-a667-4370de4b6d92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#mistral prompt format\n",
    "# <s>[INST] Instruction [/INST] Model answer</s>[INST] Follow-up instruction [/INST]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d82d7f7-fd1b-4d54-9a1f-50d3843e1288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#prompt = f'<s>[INST] Can you summarize this text? {sample_text} [/INST]'\n",
    "#prompt = f'<s>[INST] {text} [/INST]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31c56186-9f46-42d8-8e2b-3ad6dd985251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"can you tell me about yourself?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13f54d6b-27e3-4387-9836-87490dfebe58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_inputs = tokenizer([prompt], return_tensors=\"pt\").to('cuda');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd03e2da-f2e4-46b9-8c25-0e3c0abe2132",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_inputs.input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5969020-088b-4b7c-ada8-76258943a444",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s> can you tell me about yourself?\\n\\nI’m a 20-year-old college student from the United States. I’m currently studying at the University of California, Berkeley. I’m a student of the arts, and I’m currently studying at the University of California, Berkeley. I’m a student of the arts, and I’m currently studying at the University of California, Berkeley. I’m a student of the arts, and I’m currently studying at the University of California, Berkeley. I’m a student of the arts, and I’m currently studying at the University of California, Berkeley. I’m a student of the arts, and I’m currently studying at the University of California, Berkeley. I’m a student of the arts, and I’m currently studying at the University of California, Berkeley. I’m a student of the arts, and I’m currently studying at the University of California, Berkeley. I’m a student of the arts, and I’m currently studying at the University of California, Berkeley. I’m a student of the arts, and I’m currently studying at the University of California, Berkeley. I’m a student of the arts, and'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids = model.generate(**model_inputs, max_new_tokens=250,)#do_sample=True)\n",
    "tokenizer.batch_decode(generated_ids)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80d03f2d-4255-4ff2-9421-b9e64f68ee25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model_inputs.input_ids\n",
    "token_dict = dict(zip(tokenizer.vocab.values(), tokenizer.vocab.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41920093-7714-4217-9531-6a130a7dd34b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44fc457f-4d63-4bd1-8711-139ea1c1c6fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20533])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs.input_ids.to('cpu').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9085cd9c-0e40-4455-8e3c-dae3ce0c5731",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     <s>\n",
       "1     <s>\n",
       "2      ▁[\n",
       "3    INST\n",
       "4       ]\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text_tokens = pd.Series(model_inputs.input_ids.to('cpu').squeeze()).map(token_dict)\n",
    "sample_text_tokens.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f210bf3-d0da-4278-a295-93e3411fb787",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         <s>\n",
       "1         <s>\n",
       "2          ▁[\n",
       "3        INST\n",
       "4           ]\n",
       "5        ▁Can\n",
       "6        ▁you\n",
       "7        ▁sum\n",
       "8           m\n",
       "9         ara\n",
       "10        ize\n",
       "11      ▁this\n",
       "12      ▁text\n",
       "13          ?\n",
       "14          ▁\n",
       "15     <0x0A>\n",
       "16         ▁▁\n",
       "17     <0x0A>\n",
       "18         ▁▁\n",
       "19     <0x0A>\n",
       "20       ▁▁▁▁\n",
       "21     <0x0A>\n",
       "22      ▁▁▁▁▁\n",
       "23     ▁Front\n",
       "24     ▁Micro\n",
       "25         bi\n",
       "26         ol\n",
       "27     <0x0A>\n",
       "28      ▁▁▁▁▁\n",
       "29     ▁Front\n",
       "30     ▁Micro\n",
       "31         bi\n",
       "32         ol\n",
       "33     <0x0A>\n",
       "34      ▁▁▁▁▁\n",
       "35     ▁Front\n",
       "36          .\n",
       "37     ▁Micro\n",
       "38         bi\n",
       "39         ol\n",
       "40          .\n",
       "41     <0x0A>\n",
       "42     ▁▁▁▁▁▁\n",
       "43     <0x0A>\n",
       "44    ▁▁▁▁▁▁▁\n",
       "45     ▁Front\n",
       "46       iers\n",
       "47        ▁in\n",
       "48     ▁Micro\n",
       "49         bi\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text_tokens[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfc37fe-7913-445f-a3b0-a3c7ce76d05c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
